<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[前端工程——基础篇]]></title>
    <url>%2F2015%2F06%2F28%2F%E5%89%8D%E7%AB%AF%E5%B7%A5%E7%A8%8B%E2%80%94%E2%80%94%E5%9F%BA%E7%A1%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[前端工程——基础篇 喂喂喂，那个切图的，把页面写好就发给研发工程师套模板吧。 你好，切图仔。 不知道你的团队如何定义前端开发，据我所知，时至今日仍然有很多团队会把前端开发归类为产品或者设计岗位，虽然身份之争多少有些无谓，但我对这种偏见还是心存芥蒂，酝酿了许久，决定写一个系列的文章，试着从工程的角度系统的介绍一下我对前端，尤其是Web前端的理解。 只要我们还把自己的工作看作为一项软件开发活动，那么我相信读过下面的内容你也一定会有所共鸣。 前端，是一种GUI软件现如今前端可谓包罗万象，产品形态五花八门，涉猎极广，什么高大上的基础库/框架，拽炫酷的宣传页面，还有屌炸天的小游戏……不过这些一两个文件的小项目并非是前端技术的主要应用场景，更具商业价值的则是复杂的Web应用，它们功能完善，界面繁多，为用户提供了完整的产品体验，可能是新闻聚合网站，可能是在线购物平台，可能是社交网络，可能是金融信贷应用，可能是音乐互动社区，也可能是视频上传与分享平台…… 从本质上讲，所有Web应用都是一种运行在网页浏览器中的软件，这些软件的图形用户界面（Graphical User Interface，简称GUI）即为前端。 如此复杂的Web应用，动辄几十上百人共同开发维护，其前端界面通常也颇具规模，工程量不亚于一般的传统GUI软件： 尽管Web应用的复杂程度与日俱增，用户对其前端界面也提出了更高的要求，但时至今日仍然没有多少前端开发者会从软件工程的角度去思考前端开发，来助力团队的开发效率，更有甚者还对前端保留着”如玩具般简单“的刻板印象，日复一日，刀耕火种。 历史悠久的前端开发，始终像是放养的野孩子，原始如斯，不免让人慨叹！ 前端工程的三个阶段现在的前端开发倒也并非一无所有，回顾一下曾经经历过或听闻过的项目，为了提升其前端开发效率和运行性能，前端团队的工程建设大致会经历三个阶段： 第一阶段：库/框架选型 前端工程建设的第一项任务就是根据项目特征进行技术选型。 基本上现在没有人完全从0开始做网站，哪怕是政府项目用个jquery都很正常吧，React/Angularjs等框架横空出世，解放了不少生产力，合理的技术选型可以为项目节省许多工程量这点毋庸置疑。 第二阶段：简单构建优化 选型之后基本上就可以开始敲码了，不过光解决开发效率还不够，必须要兼顾运行性能。前端工程进行到第二阶段会选型一种构建工具，对代码进行压缩，校验，之后再以页面为单位进行简单的资源合并。 前端开发工程化程度之低，常常出乎我的意料，我之前在百度工作时是没有多少概念的，直到离开大公司的温室，去到业界与更多的团队交流才发现，能做到这个阶段在业界来说已然超出平均水平，属于“具备较高工程化程度”的团队了，查看网上形形色色的网页源代码，能做到最基本的JS/CSS压缩的Web应用都已跨入标准互联网公司行列，不难理解为什么很多前端团队对于前端工程构建的认知还仅停留在“压缩、校验、合并”这种程度。 第三阶段：JS/CSS模块化开发 分而治之是软件工程中的重要思想，是复杂系统开发和维护的基石，这点放在前端开发中同样适用。在解决了基本开发效率运行效率问题之后，前端团队开始思考维护效率，模块化是目前前端最流行的分治手段。 很多人觉得模块化开发的工程意义是复用，我不太认可这种看法，在我看来，模块化开发的最大价值应该是分治，是分治，分治！（重说三）。 不管你将来是否要复用某段代码，你都有充分的理由将其分治为一个模块。 JS模块化方案很多，AMD/CommonJS/UMD/ES6 Module等，对应的框架和工具也一大堆，说起来很烦，大家自行百度吧；CSS模块化开发基本都是在less、sass、stylus等预处理器的import/mixin特性支持下实现的。 虽然这些技术由来已久，在如今这个“言必及React”的时代略显落伍，但想想业界的绝大多数团队的工程化落后程度，放眼望去，毫不夸张的说，能达到第三阶段的前端团队已属于高端行列，基本具备了开发维护一般规模Web应用的能力。 然而，做到这些就够了么？Naive！ 第四阶段 前端是一种技术问题较少、工程问题较多的软件开发领域。 当我们要开发一款完整的Web应用时，前端将面临更多的工程问题，比如： 大体量：多功能、多页面、多状态、多系统； 大规模：多人甚至多团队合作开发； 高性能：CDN部署、缓存控制、文件指纹、缓存复用、请求合并、按需加载、同步/异步加载、移动端首屏CSS内嵌、HTTP 2.0服务端资源推送。 扩展阅读：大公司里怎样开发和部署前端代码？ 这些无疑是一系列严肃的系统工程问题。 前面讲的三个阶段虽然相比曾经“茹毛饮血”的时代进步不少，但用于支撑第四阶段的多人合作开发以及精细的性能优化似乎还欠缺点什么。 到底，缺什么呢？ 没有银弹读过《人月神话》的人应该都听说过，软件工程 没有银弹。没错，前端开发同样没有银弹，可是现在是连™铅弹都没有的年月！（刚有了BB弹，摔） 前端历来以“简单”著称，在前端开发者群体中，小而美的价值观占据着主要的话语权，甚至成为了某种信仰，想与其他人交流一下工程方面的心得，得到的回应往往都是两个字：太重。 重你妹！你的脑容量只有4K吗？ 工程方案其实也可以小而美！只不过它的小而美不是指代码量，而是指“规则”。找到问题的根源，用最少最简单明了的规则制定出最容易遵守最容易理解的开发规范或工具，以提升开发效率和工程质量，这同样是小而美的典范！ 2011年我有幸参与到 FIS 项目中，与百度众多大中型项目的前端研发团队共同合作，不断探索实践前端开发的工程化解决方案，13年离开百度去往UC，面对完全不同的产品形态，不同的业务场景，不同的适配终端，甚至不同的网络环境，过往的方法论仍然能够快速落地，为多个团队的不同业务场景量身定制出合理的前端解决方案。 这些经历让我明悟了一个道理： 进入第四阶段，我们只需做好两件事就能大幅提升前端开发效率，并且兼顾运行性能，那就是——组件化开发与资源管理。 第一件事：组件化开发分治的确是非常重要的工程优化手段。在我看来，前端作为一种GUI软件，光有JS/CSS的模块化还不够，对于UI组件的分治也有着同样迫切的需求： 如上图，这是我所信仰的前端组件化开发理念，简单解读一下： 页面上的每个 独立的 可视/可交互区域视为一个组件； 每个组件对应一个工程目录，组件所需的各种资源都在这个目录下就近维护； 由于组件具有独立性，因此组件与组件之间可以 自由组合； 页面只不过是组件的容器，负责组合组件形成功能完整的界面； 当不需要某个组件，或者想要替换组件时，可以整个目录删除/替换。 其中第二项描述的就近维护原则，是我觉得最具工程价值的地方，它为前端开发提供了很好的分治策略，每个开发者都将清楚的知道，自己所开发维护的功能单元，其代码必然存在于对应的组件目录中，在那个目录下能找到有关这个功能单元的所有内部逻辑，样式也好，JS也好，页面结构也好，都在那里。 组件化开发具有较高的通用性，无论是前端渲染的单页面应用，还是后端模板渲染的多页面应用，组件化开发的概念都能适用。组件HTML部分根据业务选型的不同，可以是静态的HTML文件，可以是前端模板，也可以是后端模板： 不同的技术选型决定了不同的组件封装和调用策略。 基于这样的工程理念，我们很容易将系统以独立的组件为单元进行分工划分： 由于系统功能被分治到独立的模块或组件中，粒度比较精细，组织形式松散，开发者之间不会产生开发时序的依赖，大幅提升并行的开发效率，理论上允许随时加入新成员认领组件开发或维护工作，也更容易支持多个团队共同维护一个大型站点的开发。 结合前面提到的模块化开发，整个前端项目可以划分为这么几种开发概念： 名称 说明 举例 JS模块 独立的算法和数据单元 浏览器环境检测(detect)，网络请求(ajax)，应用配置(config)，DOM操作(dom)，工具函数(utils)，以及组件里的JS单元 CSS模块 独立的功能性样式单元 栅格系统(grid)，字体图标(icon-fonts)，动画样式(animate)，以及组件里的CSS单元 UI组件 独立的可视/可交互功能单元 页头(header)，页尾(footer)，导航栏(nav)，搜索框(search) 页面 前端这种GUI软件的界面状态，是UI组件的容器 首页(index)，列表页(list)，用户管理(user) 应用 整个项目或整个站点被称之为应用，由多个页面组成 以上5种开发概念以相对较少的规则组成了前端开发的基本工程结构，基于这些理念，我眼中的前端开发就成了这个样子： 示意图 描述 整个Web应用由页面组成 页面由组件组成 一个组件一个目录，资源就近维护 组件可组合，组件的JS可依赖其他JS模块，CSS可依赖其他CSS单元 综合上面的描述，对于一般中小规模的项目，大致可以规划出这样的源码目录结构： 如果项目规模较大，涉及多个团队协作，还可以将具有相关业务功能的页面组织在一起，形成一个子系统，进一步将整个站点拆分出多个子系统来分配给不同团队维护，针对这种情况后面我会单开文章详细介绍。 以上架构设计历经许多不同公司不同业务场景的前端团队验证，收获了不错的口碑，是行之有效的前端工程分治方案。 吐槽：我本人非常反对某些前端团队将前端开发划分为“JS开发”和“页面重构”两种岗位，更倾向于组件粒度的开发理念，对GUI软件开发的分工规划应该以功能为单位，而不是开发语言；对开发者的技术要求也应该是掌握完整的端内技术。 第二件事：“智能”静态资源管理上面提到的模块化/组件化开发，仅仅描述了一种开发理念，也可以认为是一种开发规范，倘若你认可这规范，对它的分治策略产生了共鸣，那我们就可以继续聊聊它的具体实现了。 很明显，模块化/组件化开发之后，我们最终要解决的，就是模块/组件加载的技术问题。然而前端与客户端GUI软件有一个很大的不同： 前端是一种远程部署，运行时增量下载的GUI软件 前端应用没有安装过程，其所需程序资源都部署在远程服务器，用户使用浏览器访问不同的页面来加载不同的资源，随着页面访问的增加，渐进式的将整个程序下载到本地运行，“增量下载”是前端在工程上有别于客户端GUI软件的根本原因。 上图展示了一款界面繁多功能丰富的应用，如果采用Web实现，相信也是不小的体量，如果用户第一次访问页面就强制其加载全站静态资源再展示，相信会有很多用户因为失去耐心而流失。根据“增量”的原则，我们应该精心规划每个页面的资源加载策略，使得用户无论访问哪个页面都能按需加载页面所需资源，没访问过的无需加载，访问过的可以缓存复用，最终带来流畅的应用体验。 这正是Web应用“免安装”的魅力所在。 由“增量”原则引申出的前端优化技巧几乎成为了性能优化的核心，有加载相关的按需加载、延迟加载、预加载、请求合并等策略；有缓存相关的浏览器缓存利用，缓存更新、缓存共享、非覆盖式发布等方案；还有复杂的BigRender、BigPipe、Quickling、PageCache等技术。这些优化方案无不围绕着如何将增量原则做到极致而展开。 所以我觉得： 第四阶段前端开发最迫切需要做好的就是在基础架构中贯彻增量原则。 相信这种贯彻不会随着时间的推移而改变，在可预见的未来，无论在HTTP1.x还是HTTP2.0时代，无论在ES5亦或者ES6/7时代，无论是AMD/CommonJS/UMD亦或者ES6 module时代，无论端内技术如何变迁，我们都有足够充分的理由要做好前端程序资源的增量加载。 正如前面说到的，第三阶段前端工程缺少点什么呢？我觉得是在其基础架构中缺少这样一种“智能”的资源加载方案。没有这样的方案，很难将前端应用的规模发展到第四阶段，很难实现落地前面介绍的那种组件化开发方案，也很难让多方合作高效率的完成一项大型应用的开发，并保证其最终运行性能良好。在第四阶段，我们需要强大的工程化手段来管理”玩具般简单“的前端开发。 在我的印象中，Facebook是这方面探索的伟大先驱之一，早在2010年的Velocity China大会上，来自Facebook的David Wei博士就为业界展示了他们令人惊艳的静态网页资源管理和优化技术。 David Wei博士在当年的交流会上提到过一些关于Facebook的一些产品数据： Facebook整站有10000+个静态资源； 每个静态资源都有可能被翻译成超过100种语言版本； 每种资源又会针对浏览器生成3种不同的版本； 要针对不同带宽的用户做5种不同的打包方法； 有3、4个不同的用户组，用于小批次体验新的产品功能； 还要考虑不同的送达方法，可以直接送达，或者通过iframe的方式提升资源并行加载的速度； 静态资源的压缩和非压缩状态可切换，用于调试和定位线上问题 这是一个状态爆炸的问题，将所有状态乘起来，整个网站的资源组合方式会达到几百万种之多（去重之后统计大概有300万种组合方式）。支撑这么大规模前端项目运行的底层架构正是魏博士在那次演讲中分享的Static Resource Management System(静态资源管理系统)，用以解决Facebook项目中有关前端工程的3D问题（Development，Deployment，Debugging）。 那段时间 FIS 项目正好遇到瓶颈，当时的FIS还是一个用php写的task-based构建工具，那时候对于前端工程的认知度很低，觉得前端构建不就是几个压缩优化校验打包任务的组合吗，写好流程调度，就针对不同需求写插件呗，看似非常简单。但当我们支撑越来越多的业务团队，接触到各种不同的业务场景时，我们深刻的感受到task-based工具的粗糙，团队每天疲于根据各种业务场景编写各种打包插件，构建逻辑异常复杂，隐隐看到不可控的迹象。 我们很快意识到把基础架构放到构建工具中实现是一件很愚蠢的事，试图依靠构建工具实现各种优化策略使得构建变成了一个巨大的黑盒，一旦发生问题，定位起来非常困难，而且每种业务场景都有不同的优化需求，构建工具只能通过静态分析来优化加载，具有很大的局限性，单页面/多页面/PC端/移动端/前端渲染/后端渲染/多语言/多皮肤/高级优化等等资源加载问题，总不能给每个都写一套工具吧，更何况这些问题彼此之间还可以有多种组合应用，工具根本写不过来。 Facebook的做法无疑为我们亮起了一盏明灯，不过可惜它并不开源（不是技术封锁，而是这个系统依赖FB体系中的其他方面，通用性不强，开源意义不大），我们只能尝试挖掘相关信息，网上对它的完整介绍还是非常非常少，分析facebook的前端代码也没有太多收获，后来无意中发现了facebook使用的项目管理工具phabricator中的一个静态管理方案Celerity，以及相关的说明，看它的描述很像是Facebook静态资源管理系统的一个mini版！ 简单看过整个系统之后发现原理并不复杂（小而美的典范），它是通过一个小工具扫描所有静态资源，生成一张资源表，然后有一个PHP实现的资源管理框架（Celerity）提供了资源加载接口，替代了传统的script/link等静态的资源加载标签，最终通过查表来加载资源。 虽然没有真正看过FB的那套系统，但眼前的这个小小的框架给了当时的我们足够多的启示： 静态资源管理系统 = 资源表 + 资源加载框架 多么优雅的实现啊！ 资源表是一份数据文件（比如JSON），是项目中所有静态资源（主要是JS和CSS）的构建信息记录，通过构建工具扫描项目源码生成，是一种k-v结构的数据，以每个资源的id为key，记录了资源的类别、部署路径、依赖关系、打包合并等内容，比如： 12345678910111213141516&#123; "a.js": &#123; "url": "/static/js/a.5f100fa.js", "dep": [ "b.js", "a.css" ] &#125;, "a.css": &#123; "url": "/static/css/a.63cf374.css", "dep": [ "button.css" ] &#125;, "b.js": &#123; "url": "/static/js/b.97193bf.js" &#125;, "button.css": &#123; "url": "/static/css/button.de33108.css" &#125;&#125; 而资源加载框架则提供一些资源引用的API，让开发者根据id来引用资源，替代静态的script/link标签来收集、去重、按需加载资源。调用这些接口时，框架通过查表来查找资源的各项信息，并递归查找其依赖的资源的信息，然后我们可以在这个过程中实现各种性能优化算法来“智能”加载资源。 根据业务场景的不同，加载框架可以在浏览器中用JS实现，也可以是后端模板引擎中用服务端语言实现，甚至二者的组合，不一而足。 有关加载框架的具体实现我曾写过很多文章介绍，可以扩展阅读： 前端工程与性能优化 前端工程与模块化框架 这种设计很快被验证具有足够的灵活性，能够完美支撑不同团队不同技术规范下的性能优化需求，前面提到的按需加载、延迟加载、预加载、请求合并、文件指纹、CDN部署、Bigpipe、Quickling、BigRender、首屏CSS内嵌、HTTP 2.0服务端推送等等性能优化手段都可以很容易的在这种架构上实现，甚至可以根据性能日志自动进行优化（Facebook已实现）。 因为有了资源表，我们可以很方便的控制资源加载，通过各种手段在运行时计算页面的资源使用情况，从而获得最佳加载性能。无论是前端渲染的单页面应用，还是后端渲染的多页面应用，这种方法都同样适用。 此外，它还很巧妙的约束了构建工具的职责——只生成资源表。资源表是非常通用的数据结构，无论什么业务场景，其业务代码最终都可以被扫描为相同结构的表数据，并标记资源间的依赖关系，有了表之后我们只需根据不同的业务场景定制不同的资源加载框架就行了，从此彻底告别一个团队维护一套工具的时代！！！ 恩，如你所见，虽然彻底告别了一个团队一套工具的时代，但似乎又进入了一个团队一套框架的时代。其实还是有差别的，因为框架具有很大的灵活性，而且不那么黑盒，采用框架实现资源管理相比构建更容易调试、定位和升级变更。 深耕静态资源加载框架可以带来许多收益，而且有足够的灵活性和健壮性面向未来的技术变革，这个我们留作后话。 总结回顾一下前面提到过的前端工程三个阶段： 第一阶段：库/框架选型 第二阶段：简单构建优化 第三阶段：JS/CSS模块化开发 现在补充上第四阶段： 第四阶段：组件化开发与资源管理 由于先天缺陷，前端相比其他软件开发，在基础架构上更加迫切的需要组件化开发和资源管理，而解决资源管理的方法其实一点也不复杂： 一个通用的资源表生成工具 + 基于表的资源加载框架 近几年来各种你听到过的各种资源加载优化策略大部分都可以在这样一套基础上实现，而这种优化对于业务来说是完全透明的，不需要重构的性能优化——这不正是我们一直所期盼的吗？正如魏小亮博士所说：我们可以把优秀的人集中起来去优化加载。 如何选型技术、如何定制规范、如何分治系统、如何优化性能、如何加载资源，当你从切图开始转变为思考这些问题的时候，我想说： 你好，工程师！ 前端工程其实是一个很大的话题，开发仅是其中的一部分。 相关文章： 前端工程——工具篇 前端工程——框架篇 前端工程——架构篇 前端工程——流程篇 前端工程——监控篇 前端工程——测试篇]]></content>
  </entry>
  <entry>
    <title><![CDATA[前端工程与性能优化]]></title>
    <url>%2F2015%2F05%2F24%2F%E5%89%8D%E7%AB%AF%E5%B7%A5%E7%A8%8B%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前端工程与性能优化每个参与过开发企业级web应用的前端工程师或许都曾思考过前端性能优化方面的问题。我们有雅虎14条性能优化原则，还有两本很经典的性能优化指导书：《高性能网站建设指南》、《高性能网站建设进阶指南》。经验丰富的工程师对于前端性能优化方法耳濡目染，基本都能一一列举出来。这些性能优化原则大概是在7年前提出的，对于web性能优化至今都有非常重要的指导意义。 然而，对于构建大型web应用的团队来说，要坚持贯彻这些优化原则并不是一件十分容易的事。因为优化原则中很多要求是与工程管理相违背的，比如 把css放在头部 和 把js放在尾部 这两条原则，我们不能让团队的工程师在写样式和脚本引用的时候都去修改一个相同的页面文件。这样做会严重影响团队成员间并行开发的效率，尤其是在团队有版本管理的情况下，每天要花大量的时间进行代码修改合并，这项成本是难以接受的。因此在前端工程界，总会看到周期性的性能优化工作，辛勤的前端工程师们每到月圆之夜就会倾巢出动根据优化原则做一次性能优化。 性能优化是一个工程问题 本文将从一个全新的视角来思考web性能优化与前端工程之间的关系，揭示前端性能优化在前端架构及开发工具设计层面的实现思路。 性能优化原则及分类po主先假设本文的读者是有前端开发经验的工程师，并对企业级web应用开发及性能优化有一定的思考，因此我不会重复介绍雅虎14条性能优化原则。如果您没有这些前续知识，请移步 这里 来学习。 首先，我们把雅虎14条优化原则，《高性能网站建设指南》以及《高性能网站建设进阶指南》中提到的优化点做一次梳理，按照优化方向分类，可以得到这样一张表格： 优化方向 优化手段 请求数量 合并脚本和样式表，CSS Sprites，拆分初始化负载，划分主域 请求带宽 开启GZip，精简JavaScript，移除重复脚本，图像优化 缓存利用 使用CDN，使用外部JavaScript和CSS，添加Expires头，减少DNS查找，配置ETag，使AjaX可缓存 页面结构 将样式表放在顶部，将脚本放在底部，尽早刷新文档的输出 代码校验 避免CSS表达式，避免重定向 目前大多数前端团队可以利用 yui compressor 或者 google closure compiler 等压缩工具很容易做到 精简Javascript 这条原则；同样的，也可以使用图片压缩工具对图像进行压缩，实现 图像优化 原则。这两条原则是对单个资源的处理，因此不会引起任何工程方面的问题。很多团队也通过引入代码校验流程来确保实现 避免css表达式 和 避免重定向 原则。目前绝大多数互联网公司也已经开启了服务端的Gzip压缩，并使用CDN实现静态资源的缓存和快速访问；一些技术实力雄厚的前端团队甚至研发出了自动CSS Sprites工具，解决了CSS Sprites在工程维护方面的难题。使用“查找-替换”思路，我们似乎也可以很好的实现 划分主域 原则。 我们把以上这些已经成熟应用到实际生产中的优化手段去除掉，留下那些还没有很好实现的优化原则。再来回顾一下之前的性能优化分类： 优化方向 优化手段 请求数量 合并脚本和样式表，拆分初始化负载 请求带宽 移除重复脚本 缓存利用 添加Expires头，配置ETag，使Ajax可缓存 页面结构 将样式表放在顶部，将脚本放在底部，尽早刷新文档的输出 有很多顶尖的前端团队可以将上述还剩下的优化原则也都一一解决，但业界大多数团队都还没能很好的解决这些问题。因此，本文将就这些原则的解决方案做进一步的分析与讲解，从而为那些还没有进入前端工业化开发的团队提供一些基础技术建设意见，也借此机会与业界顶尖的前端团队在工业化工程化方向上交流一下彼此的心得。 静态资源版本更新与缓存缓存利用 分类中保留了 添加Expires头 和 配置ETag 两项。或许有些人会质疑，明明这两项只要配置了服务器的相关选项就可以实现，为什么说它们难以解决呢？确实，开启这两项很容易，但开启了缓存后，我们的项目就开始面临另一个挑战： 如何更新这些缓存？ 相信大多数团队也找到了类似的答案，它和《高性能网站建设指南》关于“添加Expires头”所说的原则一样——修订文件名。即： 最有效的解决方案是修改其所有链接，这样，全新的请求将从原始服务器下载最新的内容。 思路没错，但要怎么改变链接呢？变成什么样的链接才能有效更新缓存，又能最大限度避免那些没有修改过的文件缓存不失效呢？ 先来看看现在一般前端团队的做法： 1234567&lt;h1&gt;hello world&lt;/h1&gt;&lt;script type="text/javascript" src="a.js?t=201503241123"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="b.js?t=201503241123"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="c.js?t=201503241123"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="d.js?t=201503241123"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="e.js?t=201503241123"&gt;&lt;/script&gt; ps: 也有团队采用构建版本号为静态资源请求添加query，它们在本质上是没有区别的，在此就不赘述了。 接下来，项目升级，比如页面上的html结构发生变化，对应还要修改 a.js 这个文件，得到的构建结果如下： 1234567&lt;header&gt;hello world&lt;/header&gt;&lt;script type="text/javascript" src="a.js?t=201503241826"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="b.js?t=201503241826"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="c.js?t=201503241826"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="d.js?t=201503241826"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="e.js?t=201503241826"&gt;&lt;/script&gt; 为了触发用户浏览器的缓存更新，我们需要更改静态资源的url地址，如果采用构建信息（时间戳、版本号等）作为url修改的依据，如上述代码所示，我们只修改了一个a.js文件，但再次构建会让所有请求都更改了url地址，用户再度访问页面那些没有修改过的静态资源的(b.js，b.js，c.js，d.js，e.js)的浏览器缓存也一同失效了。 使用构建信息作为静态资源更新标记会导致每次构建发布后所有静态资源都被迫更新，浏览器缓存利用率降低，给性能带来伤害。 此外，采用添加query的方式来清除缓存还有一个弊端，就是 覆盖式发布 的上线问题。 采用query更新缓存的方式实际上要覆盖线上文件的，index.html和a.js总有一个先后的顺序，从而中间出现一段或大或小的时间间隔。尤其是当页面是后端渲染的模板的时候，静态资源和模板是部署在不同的机器集群上的，上线的过程中，静态资源和页面文件的部署时间间隔可能会非常长，对于一个大型互联网应用来说即使在一个很小的时间间隔内，都有可能出现新用户访问。在这个时间间隔中，访问了网站的用户会发生什么情况呢？ 如果先覆盖index.html，后覆盖a.js，用户在这个时间间隙访问，会得到新的index.html配合旧的a.js的情况，从而出现错误的页面。 如果先覆盖a.js，后覆盖index.html，用户在这个间隙访问，会得到旧的index.html配合新的a.js的情况，从而也出现了错误的页面。 这就是为什么大型web应用在版本上线的过程中经常会较集中的出现前端报错日志的原因，也是一些互联网公司选择加班到半夜等待访问低峰期再上线的原因之一。 对于静态资源缓存更新的问题，目前来说最优方案就是 基于文件内容的hash版本冗余机制 了。也就是说，我们希望项目源码是这么写的： 1&lt;script type="text/javascript" src="a.js"&gt;&lt;/script&gt; 发布后代码变成 1&lt;script type="text/javascript" src="a_8244e91.js"&gt;&lt;/script&gt; 也就是a.js发布出来后被修改了文件名，产生一个新文件，并不是覆盖已有文件。其中”_82244e91”这串字符是根据a.js的文件内容进行hash运算得到的，只有文件内容发生变化了才会有更改。由于将文件发布为带有hash的新文件，而不是同名文件覆盖，因此不会出现上述说的那些问题。同时，这么做还有其他的好处： 上线的a.js不是同名文件覆盖，而是文件名+hash的冗余，所以可以先上线静态资源，再上线html页面，不存在间隙问题； 遇到问题回滚版本的时候，无需回滚a.js，只须回滚页面即可； 由于静态资源版本号是文件内容的hash，因此所有静态资源可以开启永久强缓存，只有更新了内容的文件才会缓存失效，缓存利用率大增； 以文件内容的hash值为依据生产新文件的非覆盖式发布策略是解决静态资源缓存更新最有效的手段。 虽然这种方案是相比之下最完美的解决方案，但它无法通过手工的形式来维护，因为要依靠手工的形式来计算和替换hash值，并生成相应的文件，将是一项非常繁琐且容易出错的工作，因此我们需要借助工具来处理。 用grunt来实现md5功能是非常困难的，因为grunt只是一个task管理器，而md5计算需要构建工具具有递归编译的能，而不是简单的任务调度。考虑这样的例子： 由于我们的资源版本号是通过对文件内容进行hash运算得到，如上图所示，index.html中引用的a.css文件的内容其实也包含了a.png的hash运算结果，因此我们在修改index.html中a.css的引用时，不能直接计算a.css的内容hash，而是要先计算出a.png的内容hash，替换a.css中的引用，得到了a.css的最终内容，再做hash运算，最后替换index.html中的引用。 计算index.html中引用的a.css文件的url过程： 压缩a.png后计算其内容的md5值 将a.png的md5写入a.css，再压缩a.css，计算其内容的md5值 将a.css的md5值写入到index.html中 grunt等task-based的工具是很难在task之间协作处理这样的需求的。 在解决了基于内容hash的版本更新问题之后，我们可以将所有前端静态资源开启永久强缓存，每次版本发布都可以首先让静态资源全量上线，再进一步上线模板或者页面文件，再也不用担心各种缓存和时间间隙的问题了！ 静态资源管理与模块化框架解决了静态资源缓存问题之后，让我们再来看看前面的优化原则表还剩些什么： 优化方向 优化手段 请求数量 合并脚本和样式表，拆分初始化负载 请求带宽 移除重复脚本 缓存利用 使Ajax可缓存 页面结构 将样式表放在顶部，将脚本放在底部，尽早刷新文档的输出 很不幸，剩下的优化原则都不是使用工具就能很好实现的。或许有人会辩驳：“我用某某工具可以实现脚本和样式表合并”。嗯，必须承认，使用工具进行资源合并并替换引用或许是一个不错的办法，但在大型web应用，这种方式有一些非常严重的缺陷，来看一个很熟悉的例子 ： 某个web产品页面有A、B、C三个资源 工程师根据“减少HTTP请求”的优化原则合并了资源 产品经理要求C模块按需出现，此时C资源已出现多余的可能 C模块不再需要了，注释掉吧！代码1秒钟搞定，但C资源通常不敢轻易剔除 不知不觉中，性能优化变成了性能恶化…… 这个例子来自 Facebook静态网页资源的管理和优化@Velocity China 2010 事实上，使用工具在线下进行静态资源合并是无法解决资源按需加载的问题的。如果解决不了按需加载，则必会导致资源的冗余；此外，线下通过工具实现的资源合并通常会使得资源加载和使用的分离，比如在页面头部或配置文件中写资源引用及合并信息，而用到这些资源的html组件写在了页面其他地方，这种书写方式在工程上非常容易引起维护不同步的问题，导致使用资源的代码删除了，引用资源的代码却还在的情况。因此，在工业上要实现资源合并至少要满足如下需求： 确实能减少HTTP请求，这是基本要求（合并） 在使用资源的地方引用资源（就近依赖），不使用不加载（按需） 虽然资源引用不是集中书写的，但资源引用的代码最终还能出现在页面头部（css）或尾部（js） 能够避免重复加载资源（去重） 将以上要求综合考虑，不难发现，单纯依靠前端技术或者工具处理是很难达到这些理想要求的。 接下来我会讲述一种新的模板架构设计，用以实现前面说到那些性能优化原则，同时满足工程开发和维护的需要，这种架构设计的核心思想就是： 基于依赖关系表的静态资源管理系统与模块化框架设计 考虑一段这样的页面代码： 12345678910111213&lt;html&gt;&lt;head&gt; &lt;title&gt;page&lt;/title&gt; &lt;link rel="stylesheet" type="text/css" href="a.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="b.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="c.css"/&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; content of module a &lt;/div&gt; &lt;div&gt; content of module b &lt;/div&gt; &lt;div&gt; content of module c &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 根据资源合并需求中的第二项，我们希望资源引用与使用能尽量靠近，这样将来维护起来会更容易一些，因此，理想的源码是： 123456789101112131415&lt;html&gt;&lt;head&gt; &lt;title&gt;page&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;link rel="stylesheet" type="text/css" href="a.css"/&gt; &lt;div&gt; content of module a &lt;/div&gt; &lt;link rel="stylesheet" type="text/css" href="b.css"/&gt; &lt;div&gt; content of module b &lt;/div&gt; &lt;link rel="stylesheet" type="text/css" href="c.css"/&gt; &lt;div&gt; content of module c &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 当然，把这样的页面直接送达给浏览器用户是会有严重的页面闪烁问题的，所以我们实际上仍然希望最终页面输出的结果还是如最开始的截图一样，将css放在头部输出。这就意味着，页面结构需要有一些调整，并且有能力收集资源加载需求，那么我们考虑一下这样的源码（以php为例）： 12345678910111213141516&lt;html&gt;&lt;head&gt; &lt;title&gt;page&lt;/title&gt; &lt;!--[ CSS LINKS PLACEHOLDER ]--&gt;&lt;/head&gt;&lt;body&gt; &lt;?php require_static('a.css'); ?&gt; &lt;div&gt; content of module a &lt;/div&gt; &lt;?php require_static('b.css'); ?&gt; &lt;div&gt; content of module b &lt;/div&gt; &lt;?php require_static('c.css'); ?&gt; &lt;div&gt; content of module c &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 在页面的头部插入一个html注释 &lt;!--[CSS LINKS PLACEHOLDER]--&gt; 作为占位，而将原来字面书写的资源引用改成模板接口 require_static 调用，该接口负责收集页面所需资源。 require_static接口实现非常简单，就是准备一个数组，收集资源引用，并且可以去重。最后在页面输出的前一刻，我们将require_static在运行时收集到的 a.css、b.css、c.css 三个资源拼接成html标签，替换掉注释占位 &lt;!--[CSS LINKS PLACEHOLDER]--&gt;，从而得到我们需要的页面结构。 经过实践总结，可以发现模板层面只要实现三个开发接口，就可以比较完美的实现目前遗留的大部分性能优化原则，这三个接口分别是： require_static(res_id)：收集资源加载需求的接口，参数是静态资源id。 load_widget(wiget_id)：加载拆分成小组件模板的接口。你可以叫它为widget、component或者pagelet之类的。总之，我们需要一个接口把一个大的页面模板拆分成一个个的小部分来维护，最后在原来的页面中以组件为单位来加载这些小部件。 script(code)：收集写在模板中的js脚本，使之出现的页面底部，从而实现性能优化原则中的 将js放在页面底部 原则。 实现了这些接口之后，一个重构后的模板页面的源代码可能看起来就是这样的了： 123456789101112131415&lt;html&gt;&lt;head&gt; &lt;title&gt;page&lt;/title&gt; &lt;?php require_static('jquery.js'); ?&gt; &lt;?php require_static('bootstrap.css'); ?&gt; &lt;?php require_static('bootstrap.js'); ?&gt; &lt;!--[ CSS LINKS PLACEHOLDER ]--&gt;&lt;/head&gt;&lt;body&gt; &lt;?php load_widget('a'); ?&gt; &lt;?php load_widget('b'); ?&gt; &lt;?php load_widget('c'); ?&gt; &lt;!--[ SCRIPTS PLACEHOLDER ]--&gt;&lt;/body&gt;&lt;/html&gt; 而最终在模板解析的过程中，资源收集与去重、页面script收集、占位符替换操作，最终从服务端发送出来的html代码为： 12345678910111213141516171819&lt;html&gt;&lt;head&gt; &lt;title&gt;page&lt;/title&gt; &lt;link rel="stylesheet" type="text/css" href="bootstrap.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="a.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="b.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="c.css"/&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; content of module a &lt;/div&gt; &lt;div&gt; content of module b &lt;/div&gt; &lt;div&gt; content of module c &lt;/div&gt; &lt;script type="text/javascript" src="jquery.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="bootstrap.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="a.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="b.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="c.js"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 不难看出，我们目前已经实现了 按需加载，将脚本放在底部，将样式表放在头部 三项优化原则。 前面讲到静态资源在上线后需要添加hash戳作为版本标识，那么这种使用模板语言来收集的静态资源该如何实现这项功能呢？ 答案是：静态资源依赖关系表。 考虑这样的目录结构： project ├── widget │ ├── a │ │ ├── a.css │ │ ├── a.js │ │ └── a.php │ ├── b │ │ ├── b.css │ │ ├── b.js │ │ └── b.php │ └── c │ ├── c.css │ ├── c.js │ └── c.php ├── bootstrap.css ├── bootstrap.js ├── index.php └── jquery.js 如果我们可以使用工具扫描整个project目录，然后创建一张资源表，同时记录每个资源的部署路径，得到这样的一张表： 1234567891011121314&#123; "res" : &#123; "widget/a/a.css" : "/widget/a/a_1688c82.css", "widget/a/a.js" : "/widget/a/a_ac3123s.js", "widget/b/b.css" : "/widget/b/b_52923ed.css", "widget/b/b.js" : "/widget/b/b_a5cd123.js", "widget/c/c.css" : "/widget/c/c_03cab13.css", "widget/c/c.js" : "/widget/c/c_bf0ae3f.js", "jquery.js" : "/jquery_9151577.js", "bootstrap.css" : "/bootstrap_f5ba12d.css", "bootstrap.js" : "/bootstrap_a0b3ef9.js" &#125;, "pkg" : &#123;&#125;&#125; 基于这张表，我们就很容易实现 require_static(file_id)，load_widget(widget_id) 这两个模板接口了。以load_widget为例： 12345678910111213141516171819function load_widget($id)&#123; //从json文件中读取资源表 $map = load_map(); //查找静态资源 $filename = 'widget/' . $id . '/' . $id; //查找js文件 $js = $filename . '.js'; if(isset($map['res'][$js])) &#123; //如果有对应的js资源，就收集起来 collect_js_static($map['res'][$js]); &#125; //查找css文件 $css = $filename . '.css'; if(isset($map['res'][$css])) &#123; //如果有对应的css资源，就收集起来 collect_css_static($map['res'][$css]); &#125; include $filename . '.php';&#125; 利用查表来解决md5戳的问题，这样，我们的页面最终送达给用户的结果就是这样的： 12345678910111213141516171819&lt;html&gt;&lt;head&gt; &lt;title&gt;page&lt;/title&gt; &lt;link rel="stylesheet" type="text/css" href="/bootstrap_f5ba12d.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="/widget/a/a_1688c82.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="/widget/b/b_52923ed.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="/widget/c/c_03cab13.css"/&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; content of module a &lt;/div&gt; &lt;div&gt; content of module b &lt;/div&gt; &lt;div&gt; content of module c &lt;/div&gt; &lt;script type="text/javascript" src="/jquery_9151577.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="/bootstrap_a0b3ef9.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="/widget/a/a_ac3123s.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="/widget/b/b_a5cd123.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="/widget/c/c_bf0ae3f.js"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 接下来，我们讨论基于表的设计思想上是如何实现静态资源合并的。或许有些团队使用过combo服务，也就是我们在最终拼接生成页面资源引用的时候，并不是生成多个独立的link标签，而是将资源地址拼接成一个url路径，请求一种线上的动态资源合并服务，从而实现减少HTTP请求的需求，比如前面的例子，稍作调整即可得到这样的结果： 123456789101112&lt;html&gt;&lt;head&gt; &lt;title&gt;page&lt;/title&gt; &lt;link rel="stylesheet" type="text/css" href="/??bootstrap_f5ba12d.css,widget/a/a_1688c82.css,widget/b/b_52923ed.css,widget/c/c_03cab13.css"/&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; content of module a &lt;/div&gt; &lt;div&gt; content of module b &lt;/div&gt; &lt;div&gt; content of module c &lt;/div&gt; &lt;script type="text/javascript" src="/??jquery_9151577.js,bootstrap_a0b3ef9.js,widget/a/a_ac3123s.js,widget/b/b_a5cd123.js,widget/c/c_bf0ae3f.js"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 这个 /??file1,file2,file3,… 的url请求响应就是动态combo服务提供的，它的原理很简单，就是根据url找到对应的多个文件，合并成一个文件来响应请求，并将其缓存，以加快访问速度。 这种方法很巧妙，有些服务器甚至直接集成了这类模块来方便的开启此项服务，这种做法也是大多数大型web应用的资源合并做法。但它也存在一些缺陷： 浏览器有url长度限制，因此不能无限制的合并资源。 如果用户在网站内有公共资源的两个页面间跳转访问，由于两个页面的combo的url不一样导致用户不能利用浏览器缓存来加快对公共资源的访问速度。 如果combo的url中任何一个文件发生改变，都会导致整个url缓存失效，从而导致浏览器缓存利用率降低。 对于上述第二条缺陷，可以举个例子来看说明： 假设网站有两个页面A和B A页面使用了a，b，c，d四个资源 B页面使用了a，b，e，f四个资源 如果使用combo服务，我们会得： A页面的资源引用为：/??a,b,c,d B页面的资源引用为：/??a,b,e,f 两个页面引用的资源是不同的url，因此浏览器会请求两个合并后的资源文件，跨页面访问没能很好的利用a、b这两个资源的缓存。 很明显，如果combo服务能聪明的知道A页面使用的资源引用为 /??a,b 和 /??c,d，而B页面使用的资源引用为 /??a,b 和 /??e,f就好了。这样当用户在访问A页面之后再访问B页面时，只需要下载B页面的第二个combo文件即可，第一个文件已经在访问A页面时缓存好了的。 基于这样的思考，我们在资源表上新增了一个字段，取名为 pkg，就是资源合并生成的新资源，表的结构会变成： 123456789101112131415161718192021222324252627282930313233343536373839&#123; "res" : &#123; "widget/a/a.css" : "/widget/a/a_1688c82.css", "widget/a/a.js" : "/widget/a/a_ac3123s.js", "widget/b/b.css" : "/widget/b/b_52923ed.css", "widget/b/b.js" : "/widget/b/b_a5cd123.js", "widget/c/c.css" : "/widget/c/c_03cab13.css", "widget/c/c.js" : "/widget/c/c_bf0ae3f.js", "jquery.js" : "/jquery_9151577.js", "bootstrap.css" : "/bootstrap_f5ba12d.css", "bootstrap.js" : "/bootstrap_a0b3ef9.js" &#125;, "pkg" : &#123; "p0" : &#123; "url" : "/pkg/lib_cef213d.js", "has" : [ "jquery.js", "bootstrap.js" ] &#125;, "p1" : &#123; "url" : "/pkg/lib_afec33f.css", "has" : [ "bootstrap.css" ] &#125;, "p2" : &#123; "url" : "/pkg/widgets_22feac1.js", "has" : [ "widget/a/a.js", "widget/b/b.js", "widget/c/c.js" ] &#125;, "p3" : &#123; "url" : "/pkg/widgets_af23ce5.css", "has" : [ "widget/a/a.css", "widget/b/b.css", "widget/c/c.css" ] &#125; &#125;&#125; 相比之前的表，可以看到新表中多了一个pkg字段，并且记录了打包后的文件所包含的独立资源。这样，我们重新设计一下 require_static、load_widget 这两个模板接口，实现这样的逻辑： 在查表的时候，如果一个静态资源有pkg字段，那么就去加载pkg字段所指向的打包文件，否则加载资源本身。 比如执行require_static(&#39;bootstrap.js&#39;)，查表得知bootstrap.js被打包在了p1中，因此取出p1包的url /pkg/lib_cef213d.js，并且记录页面已加载了 jquery.js 和 bootstrap.js 两个资源。这样一来，之前的模板代码执行之后得到的html就变成了： 1234567891011121314&lt;html&gt;&lt;head&gt; &lt;title&gt;page&lt;/title&gt; &lt;link rel="stylesheet" type="text/css" href="/pkg/lib_afec33f.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="/pkg/widgets_af23ce5.css"/&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; content of module a &lt;/div&gt; &lt;div&gt; content of module b &lt;/div&gt; &lt;div&gt; content of module c &lt;/div&gt; &lt;script type="text/javascript" src="/pkg/lib_cef213d.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="/pkg/widgets_22feac1.js"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 虽然这种策略请求有4个，不如combo形式的请求少，但可能在统计上是性能更好的方案。由于两个lib打包的文件修改的可能性很小，因此这两个请求的缓存利用率会非常高，每次项目发布后，用户需要重新下载的静态资源可能要比combo请求节省很多带宽。 性能优化既是一个工程问题，又是一个统计问题。优化性能时如果只关注一个页面的首次加载是很片面的。还应该考虑全站页面间跳转、项目迭代后更新资源等情况下的优化策略。 此时，我们又引入了一个新的问题：如何决定哪些文件被打包？ 从经验来看，项目初期可以采用人工配置的方式来指定打包情况，比如： 12345678&#123; "pack" : &#123; "lib.js" : [ "jquery.js", "bootstrap.js" ], "lib.css" : "bootstrap.css", "widgets.js" : "widget/**.js", "widgets.css" : "widget/**.css" &#125;&#125; 但随着系统规模的增大，人工配置会带来非常高的维护成本，此时需要一个辅助系统，通过分析线上访问日志和静态资源组合加载情况来自动生成这份配置文件，系统设计如图： 至此，我们通过基于表的静态资源管理系统和三个模板接口实现了几个重要的性能优化原则，现在我们再来回顾一下前面的性能优化原则分类表，剔除掉已经做到了的，看看还剩下哪些没做到的： 优化方向 优化手段 请求数量 拆分初始化负载 缓存利用 使Ajax可缓存 页面结构 尽早刷新文档的输出 拆分初始化负载 的目标是将页面一开始加载时不需要执行的资源从所有资源中分离出来，等到需要的时候再加载。工程师通常没有耐心去区分资源的分类情况，但我们可以利用组件化框架接口来帮助工程师管理资源的使用。还是从例子开始思考，如果我们有一个js文件是用户交互后才需要加载的，会怎样呢： 1234567891011121314151617181920212223242526&lt;html&gt;&lt;head&gt; &lt;title&gt;page&lt;/title&gt; &lt;?php require_static('jquery.js'); ?&gt; &lt;?php require_static('bootstrap.css'); ?&gt; &lt;?php require_static('bootstrap.js'); ?&gt; &lt;!--[ CSS LINKS PLACEHOLDER ]--&gt;&lt;/head&gt;&lt;body&gt; &lt;?php load_widget('a'); ?&gt; &lt;?php load_widget('b'); ?&gt; &lt;?php load_widget('c'); ?&gt; &lt;?php script('start'); ?&gt; &lt;script&gt; $(document.body).click(function()&#123; require.async('dialog.js', function(dialog)&#123; dialog.show('you catch me!'); &#125;); &#125;); &lt;/script&gt; &lt;?php script('end'); ?&gt; &lt;!--[ SCRIPTS PLACEHOLDER ]--&gt;&lt;/body&gt;&lt;/html&gt; 很明显，dialog.js 这个文件我们不需要在初始化的时候就加载，因此它应该在后续的交互中再加载，但文件都加了md5戳，我们如何能在浏览器环境中知道加载的url呢？ 答案就是：把静态资源表的一部分输出在页面上，供前端模块化框架加载静态资源。 我就不多解释代码的执行过程了，大家看到完整的html输出就能理解是怎么回事了： 123456789101112131415161718192021222324252627282930&lt;html&gt;&lt;head&gt; &lt;title&gt;page&lt;/title&gt; &lt;link rel="stylesheet" type="text/css" href="/pkg/lib_afec33f.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="/pkg/widgets_af23ce5.css"/&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; content of module a &lt;/div&gt; &lt;div&gt; content of module b &lt;/div&gt; &lt;div&gt; content of module c &lt;/div&gt; &lt;script type="text/javascript" src="/pkg/lib_cef213d.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="/pkg/widgets_22feac1.js"&gt;&lt;/script&gt; &lt;script&gt; //将静态资源表输出在前端页面中 require.config(&#123; res : &#123; 'dialog.js' : '/dialog_fa3df03.js' &#125; &#125;); &lt;/script&gt; &lt;script&gt; $(document.body).click(function()&#123; //require.async接口查表确定加载资源的url require.async('dialog.js', function(dialog)&#123; dialog.show('you catch me!'); &#125;); &#125;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; dialog.js不会在页面以script src的形式输出，而是变成了资源注册，这样，当页面点击触发require.async执行的时候，async函数才会查表找到资源的url并加载它，加载完毕后触发回调函数。 以上框架示例我实现了一个java版（ https://github.com/fouber/fis-java-jsp ）和一个php版（ https://github.com/fouber/static-resource-management-system-demo ）的示例项目，有兴趣的同学可以参考一下，比阅读文章要更直观一些。 到目前为止，我们又以架构的形式实现了一项优化原则（拆分初始化负载），回顾我们的优化分类表，现在仅有两项没能做到了： 优化方向 优化手段 缓存利用 使Ajax可缓存 页面结构 尽早刷新文档的输出 剩下的两项优化原则要做到并不容易，真正可缓存的Ajax在现实开发中比较少见，而 尽早刷新文档的输出 原则facebook在2010年的velocity上 提到过，就是BigPipe技术。当时facebook团队还讲到了Quickling和PageCache两项技术，其中的PageCache算是比较彻底的实现Ajax可缓存的优化原则了。由于篇幅关系，就不在此展开了，后续还会撰文详细解读这两项技术。 总结其实在前端开发工程管理领域还有很多细节值得探索和挖掘，提升前端团队生产力水平并不是一句空话，它需要我们能对前端开发及代码运行有更深刻的认识，对性能优化原则有更细致的分析与研究。在前端工业化开发的所有环节均有可节省的人力成本，这些成本非常可观，相信现在很多大型互联网公司也都有了这样的共识。 本文只是将这个领域中很小的一部分知识的展开讨论，抛砖引玉，希望能为业界相关领域的工作者提供一些不一样的思路。]]></content>
  </entry>
  <entry>
    <title><![CDATA[前端工程与模块化框架]]></title>
    <url>%2F2015%2F04%2F18%2F%E5%89%8D%E7%AB%AF%E5%B7%A5%E7%A8%8B%E4%B8%8E%E6%A8%A1%E5%9D%97%E5%8C%96%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[前端工程与模块化框架一直酝酿着写一篇关于模块化框架的文章，因为模块化框架是前端工程中的 最为核心的部分 。本来又想长篇大论的写一篇完整且严肃的paper，但看了 @糖饼 在 div.io 的一篇文章 《再谈 SeaJS 与 RequireJS 的差异》觉得可以借着这篇继续谈一下，加上最近spm3发布，在seajs的官网上又引来了一场 口水战 ，我并不想参与到这场论战中，各有所爱的事情不好评论什么，但我想从工程的角度来阐述一下已知的模块化框架相关的问题，并给出一些新的思路，其实也不新啦，都实践了2多年了。 前端模块化框架肩负着 模块管理、资源加载 两项重要的功能，这两项功能与工具、性能、业务、部署等工程环节都有着非常紧密的联系。因此，模块化框架的设计应该最高优先级考虑工程需要。 基于 @糖饼 的文章 《再谈 SeaJS 与 RequireJS 的差异》，我这里还要补充一些模块化框架在工程方面的缺点： requirejs和seajs二者在加载上都有缺陷，就是模块的依赖要等到模块加载完成后，通过静态分析（seajs）或者deps参数（requirejs）来获取，这就为 合并请求 和 按需加载 带来了实现上的矛盾： 要么放弃按需加载，把所有js合成一个文件，从而满足请求合并（两个框架的官方demo都有这样的例子）； 要么放弃请求合并，请求独立的模块文件，从而满足按需加载。 AMD规范在执行callback的时候，要初始化所有依赖的模块，而CMD只有执行到require的时候才初始化模块。所以用AMD实现某种if-else逻辑分支加载不同的模块的时候，就会比较麻烦了。考虑这种情况： 123456789101112//AMD for SPArequire(['page/index', 'page/detail'], function(index, detail)&#123; //在执行回调之前，index和detail模块的factory均执行过了 switch(location.hash)&#123; case '#index': index(); break; case '#detail': detail(); break; &#125;&#125;); 在执行回调之前，已经同时执行了index和detail模块的factory，而CMD只有执行到require才会调用对应模块的factory。这种差别带来的不仅仅是性能上的差异，也可能为开发增加一点小麻烦，比如不方便实现换肤功能，factory注意不要直接操作dom等。当然，我们可以多层嵌套require来解决这个问题，但又会引起模块请求串行的问题。 结论：以纯前端方式实现模块化框架 不能 同时满足 按需加载，请求合并 和 依赖管理 三个需求。 导致这个问题的根本原因是 纯前端方式只能在运行时分析依赖关系。 解决模块化管理的新思路由于根本问题出在 运行时分析依赖，因此新思路的策略很简单：不在运行时分析依赖。这就要借助 构建工具 做线下分析了，其基本原理就是： 利用构建工具在线下进行 模块依赖分析，然后把依赖关系数据写入到构建结果中，并调用模块化框架的 依赖关系声明接口 ，实现模块管理、请求合并以及按需加载等功能。 举个例子，假设我们有一个这样的工程： 12345678910project ├ lib │ └ xmd.js #模块化框架 ├ mods #模块目录 │ ├ a.js │ ├ b.js │ ├ c.js │ ├ d.js │ └ e.js └ index.html #入口页面 工程中，index.html 的源码内容为： 1234567891011121314&lt;!doctype html&gt;...&lt;script src="lib/xmd.js"&gt;&lt;/script&gt; &lt;!-- 模块化框架 --&gt;&lt;script&gt; //等待构建工具生成数据替换 `__FRAMEWORK_CONFIG__' 变量 require.config(__FRAMEWORK_CONFIG__);&lt;/script&gt;&lt;script&gt; //用户代码，异步加载模块 require.async(['a', 'e'], function(a, e)&#123; //do something with a and e. &#125;);&lt;/script&gt;... 工程中，mods/a.js 的源码内容为（采用类似CMD的书写规范）： 123456789define('a', function(require, exports, module)&#123; console.log('a.init'); var b = require('b'); var c = require('c'); exports.run = function()&#123; //do something with b and c. console.log('a.run'); &#125;;&#125;); 具体实现过程 用工具在下线对工程文件进行扫描，得到依赖关系表： 1234&#123; "a" : [ "b", "c" ], "b" : [ "d" ]&#125; 工具把依赖表构建到页面或者脚本中，并调用模块化框架的配置接口，index.html的构建结果为： 123456789101112131415161718&lt;!doctype html&gt;...&lt;script src="lib/xmd.js"&gt;&lt;/script&gt; &lt;!-- 模块化框架 --&gt;&lt;script&gt; //构建工具生成的依赖数据 require.config(&#123; "deps" : &#123; "a" : [ "b", "c" ], "b" : [ "d" ] &#125; &#125;);&lt;/script&gt;&lt;script&gt; //用户代码，异步加载模块 require.async(['a', 'e'], function(a, e)&#123; //do something with a and e. &#125;);&lt;/script&gt; 模块化框架根据依赖表加载资源，比如上述例子，入口需要加载a、e两个模块，查表得知完整依赖关系，配合combo服务，可以发起一个合并后的请求： http://www.example.com/??d.js,b.js,c.js,a.js,e.js 先来看一下这种方案的优点 采用类似CMD的书写规范（同步require函数声明依赖），可以在执行到require语句的时候才调用模块的factory。 虽然采用CMD书写规范，但放弃了运行时分析依赖，改成工具输出依赖表，因此 依赖分析完成后可以压缩掉require关键字 框架并没有严格依赖工具，它只是约定了一种数据结构。不使用工具，人工维护 require.config({...}) 相关的数据也是可以的。对于小项目，文件全部合并的情况，更加不需要deps表了，只要在入口的require.async调用之前加载所有模块化的文件，依赖关系无需额外维护 构建工具设计非常简单，而且可靠。工作就是扫描模块文件目录，得到依赖表，JSON序列化之后插入到构建代码中 由于框架预先知道所有模块的依赖关系，因此可以借助combo服务实现请求合并，而不用等到一级模块加载完成才能知道后续的依赖关系。 如果构建工具可以自动包装define函数，那么整个系统开发起来会感觉跟nodejs非常接近，比较舒服。 再来讨论一下这种方案的缺点：由于采用require函数作为依赖标记，因此如果需要变量方式require，需要额外声明，这个时候可以实现兼容AMD规范写法，比如 123456789define('a', ['b', 'c'], function(require, exports, module)&#123; console.log('a.init'); var name = isIE ? 'b' : 'c'; var mod = require(name); exports.run = function()&#123; //do something with mod. console.log('a.run'); &#125;;&#125;) 只要工具把define函数中的 deps 参数，或者factory内的require都作为依赖声明标记来识别，这样工程性就比较完备了。 但不管怎样， 线下分析始终依靠了字面量信息，所以开发上可能会有一定的局限性，但总的来说瑕不掩瑜。 希望本文能为前端模块化框架的作者带来一些新的思路。没有必要争论规范，工程问题才是最根本的问题。]]></content>
  </entry>
  <entry>
    <title><![CDATA[大公司里怎样开发和部署前端代码？]]></title>
    <url>%2F2015%2F03%2F30%2F%E5%A4%A7%E5%85%AC%E5%8F%B8%E9%87%8C%E6%80%8E%E6%A0%B7%E5%BC%80%E5%8F%91%E5%92%8C%E9%83%A8%E7%BD%B2%E5%89%8D%E7%AB%AF%E4%BB%A3%E7%A0%81%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[大公司里怎样开发和部署前端代码？ 本文搬运自 知乎问题 中的答案。 这是一个非常有趣的 非主流前端领域，这个领域要探索的是如何用工程手段解决前端开发和部署优化的综合问题，入行到现在一直在学习和实践中。 在我的印象中，facebook是这个领域的鼻祖，有兴趣、有梯子的同学可以去看看facebook的页面源代码，体会一下什么叫工程化。 接下来，我想从原理展开讲述，多图，较长，希望能有耐心看完。 让我们返璞归真，从原始的前端开发讲起。上图是一个“可爱”的index.html页面和它的样式文件a.css，用文本编辑器写代码，无需编译，本地预览，确认OK，丢到服务器，等待用户访问。前端就是这么简单，好好玩啊，门槛好低啊，分分钟学会有木有！ 然后我们访问页面，看到效果，再查看一下网络请求，200！不错，太™完美了！那么，研发完成。。。。了么？ 等等，这还没完呢！对于大公司来说，那些变态的访问量和性能指标，将会让前端一点也不“好玩”。 看看那个a.css的请求吧，如果每次用户访问页面都要加载，是不是很影响性能，很浪费带宽啊，我们希望最好这样： 利用304，让浏览器使用本地缓存。但，这样也就够了吗？不成！304叫协商缓存，这玩意还是要和服务器通信一次，我们的优化级别是变态级，所以必须彻底灭掉这个请求，变成这样： 强制浏览器使用本地缓存（cache-control/expires），不要和服务器通信。好了，请求方面的优化已经达到变态级别，那问题来了：你都不让浏览器发资源请求了，这缓存咋更新？ 很好，相信有人想到了办法：通过更新页面中引用的资源路径，让浏览器主动放弃缓存，加载新资源。好像这样： 下次上线，把链接地址改成新的版本，就更新资源了不是。OK，问题解决了么？！当然没有！大公司的变态又来了，思考这种情况： 页面引用了3个css，而某次上线只改了其中的a.css，如果所有链接都更新版本，就会导致b.css，c.css的缓存也失效，那岂不是又有浪费了？！ 重新开启变态模式，我们不难发现，要解决这种问题，必须让url的修改与文件内容关联，也就是说，只有文件内容变化，才会导致相应url的变更，从而实现文件级别的精确缓存控制。 什么东西与文件内容相关呢？我们会很自然的联想到利用 数据摘要要算法 对文件求摘要信息，摘要信息与文件内容一一对应，就有了一种可以精确到单个文件粒度的缓存控制依据了。好了，我们把url改成带摘要信息的： 这回再有文件修改，就只更新那个文件对应的url了，想到这里貌似很完美了。你觉得这就够了么？大公司告诉你：图样图森破！ 唉~~~~，让我喘口气 现代互联网企业，为了进一步提升网站性能，会把静态资源和动态网页分集群部署，静态资源会被部署到CDN节点上，网页中引用的资源也会变成对应的部署路径： 好了，当我要更新静态资源的时候，同时也会更新html中的引用吧，就好像这样： 这次发布，同时改了页面结构和样式，也更新了静态资源对应的url地址，现在要发布代码上线，亲爱的前端研发同学，你来告诉我，咱们是先上线页面，还是先上线静态资源？ 先部署页面，再部署资源：在二者部署的时间间隔内，如果有用户访问页面，就会在新的页面结构中加载旧的资源，并且把这个旧版本的资源当做新版本缓存起来，其结果就是：用户访问到了一个样式错乱的页面，除非手动刷新，否则在资源缓存过期之前，页面会一直执行错误。 先部署资源，再部署页面：在部署时间间隔之内，有旧版本资源本地缓存的用户访问网站，由于请求的页面是旧版本的，资源引用没有改变，浏览器将直接使用本地缓存，这种情况下页面展现正常；但没有本地缓存或者缓存过期的用户访问网站，就会出现旧版本页面加载新版本资源的情况，导致页面执行错误，但当页面完成部署，这部分用户再次访问页面又会恢复正常了。好的，上面一坨分析想说的就是：先部署谁都不成！都会导致部署过程中发生页面错乱的问题。所以，访问量不大的项目，可以让研发同学苦逼一把，等到半夜偷偷上线，先上静态资源，再部署页面，看起来问题少一些。 但是，大公司超变态，没有这样的“绝对低峰期”，只有“相对低峰期”。So，为了稳定的服务，还得继续追求极致啊！ 这个奇葩问题，起源于资源的 覆盖式发布，用 待发布资源 覆盖 已发布资源，就有这种问题。解决它也好办，就是实现 非覆盖式发布。 看上图，用文件的摘要信息来对资源文件进行重命名，把摘要信息放到资源文件发布路径中，这样，内容有修改的资源就变成了一个新的文件发布到线上，不会覆盖已有的资源文件。上线过程中，先全量部署静态资源，再灰度部署页面，整个问题就比较完美的解决了。 所以，大公司的静态资源优化方案，基本上要实现这么几个东西： 配置超长时间的本地缓存 —— 节省带宽，提高性能 采用内容摘要作为缓存更新依据 —— 精确的缓存控制 静态资源CDN部署 —— 优化网络请求 更资源发布路径实现非覆盖式发布 —— 平滑升级 全套做下来，就是相对比较完整的静态资源缓存控制方案了，而且，还要注意的是，静态资源的缓存控制要求在 前端所有静态资源加载的位置都要做这样的处理 。是的，所有！什么js、css自不必说，还要包括js、css文件中引用的资源路径，由于涉及到摘要信息，引用资源的摘要信息也会引起引用文件本身的内容改变，从而形成级联的摘要变化，大概示意图就是： 好了，目前我们快速的学习了一下前端工程中关于静态资源缓存要面临的优化和部署问题，新的问题又来了：这™让工程师怎么写码啊！！！ 要解释优化与工程的结合处理思路，又会扯出一堆有关模块化开发、资源加载、请求合并、前端框架等等的工程问题，以上只是开了个头，解决方案才是精髓，但要说的太多太多，有空再慢慢展开吧。 总之，前端性能优化绝逼是一个工程问题！ 以上不是我YY的，可以观察 百度 或者 facebook 的页面以及静态资源源代码，查看它们的资源引用路径处理，以及网络请中静态资源的缓存控制部分。再次赞叹facebook的前端工程建设水平，跪舔了。 建议前端工程师多多关注前端工程领域，也许有人会觉得自己的产品很小，不用这么变态，但很有可能说不定某天你就需要做出这样的改变了。而且，如果我们能把事情做得更极致，为什么不去做呢？ 另外，也不要觉得这些是运维或者后端工程师要解决的问题。如果由其他角色来解决，大家总是把自己不关心的问题丢给别人，那么前端工程师的开发过程将受到极大的限制，这种情况甚至在某些大公司都不少见！ 妈妈，我再也不玩前端了。。。。5555 业界实践Assets PipelineRails中的Assets Pipeline完成了以上所说的优化细节，对整个静态资源的管理上的设计思考也是如此，了解rails的人也可以把此答案当做是对rails中assets pipeline设计原理的分析。 rails通过把静态资源变成erb模板文件，然后加入&lt;%= asset_path ‘image.png’ %&gt;，上线前预编译完成处理，fis的实现思路跟这个几乎完全一样，但我们当初确实不知道有rails的这套方案存在。 相关资料： 英文版：http://guides.rubyonrails.org/asset_pipeline.html 中文版：http://guides.ruby-china.org/asset_pipeline.html FIS的解决方案用 F.I.S 包装了一个小工具，完整实现整个回答所说的最佳部署方案，并提供了源码对照，可以感受一下项目源码和部署代码的对照。 源码项目：fouber/static-resource-digest-project · GitHub 部署项目：fouber/static-resource-digest-project-release · GitHub 部署项目可以理解为线上发布后的结果，可以在部署项目里查看所有资源引用的md5化处理。 这个示例也可以用于和assets pipeline做比较。fis没有assets的目录规范约束，而且可以以独立工具的方式组合各种前端开发语言（coffee、less、sass/scss、stylus、markdown、jade、ejs、handlebars等等你能想到的），并与其他后端开发语言结合。 assets pipeline的设计思想值得独立成工具用于前端工程，fis就当做这样的一个选择吧。]]></content>
  </entry>
</search>
